{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMn42zxVC6TgYMd0IMVWPob"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os, sys, random, cv2\n","from skimage import io, transform, color, img_as_ubyte\n","from collections import Counter\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.feature import hog\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn import svm, metrics\n","from joblib import dump, load\n","\n","%matplotlib inline\n","# Make importing .py functions easier\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Colab setup\n","drive.mount('/content/drive')\n","!pip install opencv-python==4.5.5.64\n","!pip show opencv-python\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/CW_Folder_UG'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print('\\n\\n', (os.listdir(GOOGLE_DRIVE_PATH)), '\\n\\n')\n","CODE_PATH = os.path.join(GOOGLE_DRIVE_PATH, 'Code')\n","sys.path.append(CODE_PATH)\n","\n","# Unzip datasets\n","zip_path = os.path.join(GOOGLE_DRIVE_PATH, 'CW_Dataset.zip')\n","!cp '{zip_path}' .\n","!yes | unzip -q CW_Dataset.zip\n","!rm CW_Dataset.zip\n","\n","path_to_trainset = 'CW_Dataset/train'\n","path_to_testset = 'CW_Dataset/test'\n","#path to testset can be changed, by commenting the above line, and uncommenting the below line\n","# path_to_testset = 'Personal_Dataset'\n","\n","def load_dataset(path, desired_height, desired_width):\n","    images = []\n","    labels = []\n","    #ref: https://www.w3schools.com/python/ref_func_open.asp for opening files\n","    label_files = [file for file in os.listdir(os.path.join(path, 'labels')) if file.endswith('.txt')]\n","    for label_file in label_files:\n","        with open(os.path.join(path, 'labels', label_file), 'r') as myFile:\n","            label = int(myFile.read().strip()) #ref: https://www.w3schools.com/python/ref_string_strip.asp clean up string content\n","            labels.append(label)\n","        image_name = label_file.replace('.txt', '.jpeg')\n","        image_path = os.path.join(path, 'images', image_name)\n","        image = io.imread(image_path)\n","        image = transform.resize(image, (desired_height, desired_width))\n","        images.append(image)\n","    return images, labels\n","\n","X_train, y_train = load_dataset(path_to_trainset, desired_height=28, desired_width=28)\n","X_test, y_test = load_dataset(path_to_testset, desired_height=28, desired_width=28)\n","print(\"\\n Number of training images loaded:\", len(X_train)) #ref: https://www.w3schools.com/python/ref_func_len.asp length of list\n","print(\"\\n\\nTraining label distribution:\", Counter(y_train))\n","\n","#ref: lab05\n","def extract_hog_features(images):\n","    hog_features = []\n","    for image in images:\n","        HOG_des = hog(image, orientations=8, pixels_per_cell=(16, 16),\n","                      cells_per_block=(1, 1), visualize=False, channel_axis=2)\n","        hog_features.append(HOG_des)\n","    return np.array(hog_features)\n","\n","X_train_hog = extract_hog_features(X_train)\n","\n","# # Train Model 1 (HOG + SVM)\n","from my_train_SVM import train_linear_SVM\n","svm_classifier = train_linear_SVM(X_train_hog, y_train)\n","\n","# Train Model 2 (HOG + MLP) ref: lab06\n","mlp_classifier = MLPClassifier(hidden_layer_sizes=(50, 100), max_iter=100, alpha=1e-4,\n","                               solver='sgd', verbose=True, random_state=1,\n","                               learning_rate_init=.1)\n","mlp_classifier.fit(X_train_hog, y_train)\n","\n","#Train Model 3 (SIFT + SVM) ref: lab06\n","#ref: lab04\n","sift = cv2.SIFT_create()\n","#lists for feature descriptors and labels\n","des_list = []\n","y_train_list = []\n","\n","for i in range(len(X_train)):\n","    # Identify keypoints and extract descriptors with SIFT\n","    img = img_as_ubyte(color.rgb2gray(X_train[i]))\n","    kp, des = sift.detectAndCompute(img, None)\n","    if des is not None:\n","        des_list.append(des.astype(np.float32))\n","        y_train_list.append(y_train[i])\n","\n","# Convert to array for easier handling\n","des_array = np.vstack(des_list)\n","# codewords\n","k = len(np.unique(y_train)) * 10\n","batch_size = des_array.shape[0] // 4\n","kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size, n_init='auto').fit(des_array)\n","\n","# Convert descriptors into histograms of codewords for each image\n","hist_list = []\n","idx_list = []\n","\n","for des in des_list:\n","    hist = np.zeros(k, dtype=np.float32) # ref: https://numpy.org/doc/stable/user/basics.types.html\n","\n","    idx = kmeans.predict(des)\n","    idx_list.append(idx)\n","    for j in idx:\n","        hist[j] = hist[j] + (1 / len(des))\n","    hist_list.append(hist)\n","\n","hist_array = np.vstack(hist_list)\n","sift_classifier = svm.SVC(kernel='rbf')\n","sift_classifier.fit(hist_array, y_train_list)\n","\n","def extract_sift_descriptors(images):\n","    sift_descriptors = []\n","    for image in images:\n","        if image.ndim == 3 and image.shape[-1] == 4:\n","            img_gray = color.rgb2gray(image[:, :, :3]) # Convert RGB or RGBA to grayscale\n","        elif image.ndim == 3:\n","            img_gray = color.rgb2gray(image)\n","        else:\n","            img_gray = image # Grayscale image, no need to convert\n","\n","        img_ubyte = img_as_ubyte(img_gray)\n","        kp, des = sift.detectAndCompute(img_ubyte, None)\n","        if des is not None:\n","            sift_descriptors.append(des.astype(np.float32))\n","        else:\n","            sift_descriptors.append(np.zeros((1, 128), dtype=np.float32))\n","    return sift_descriptors\n","\n","def compute_sift_histograms(sift_descriptors):\n","    sift_hist = []\n","    for des in sift_descriptors:\n","        hist = np.zeros(k, dtype=np.float32)\n","        idx = kmeans.predict(des)\n","        for j in idx:\n","            hist[j] += 1\n","        sift_hist.append(hist)\n","    return np.vstack(sift_hist)\n","\n","def MaskDetection(path_to_testset, model_type):\n","    if model_type == 'hog_svm':\n","        X_test_hog = extract_hog_features(X_test)\n","        y_pred = svm_classifier.predict(X_test_hog)\n","    elif model_type == 'hog_mlp':\n","        X_test_hog = extract_hog_features(X_test)\n","        y_pred = mlp_classifier.predict(X_test_hog)\n","    elif model_type == 'sift_svm':\n","        sift_descriptors = extract_sift_descriptors(X_test)\n","        sift_hist_array = compute_sift_histograms(sift_descriptors)\n","        y_pred = sift_classifier.predict(sift_hist_array)\n","    else:\n","        raise ValueError(\"Unknown model type\")\n","\n","    test_sample = random.sample(range(len(X_test)), 4)\n","    fig, axes = plt.subplots(1, 4, figsize=(10, 5), sharex=True, sharey=True)\n","    ax = axes.ravel()\n","    for i in range(4):\n","        ax[i].imshow(X_test[test_sample[i]], cmap='gray')\n","        ax[i].set_title(f'Label: {y_test[test_sample[i]]} \\n Prediction: {y_pred[i]}')\n","        ax[i].set_axis_off()\n","    fig.tight_layout()\n","    plt.show()\n","    return y_pred\n","\n","print(\"\\n HOG+SVM test\")\n","y_pred_hog_svm = MaskDetection(path_to_testset, model_type='hog_svm')\n","print(\"\\n HOG+MLP test\")\n","y_pred_mlp = MaskDetection(path_to_testset, model_type='hog_mlp')\n","print(\"\\n SIFT+SVM test\")\n","y_pred_sift_svm = MaskDetection(path_to_testset, model_type='sift_svm')\n","\n","print(f\"\"\"\\n Classification report for classifier {svm_classifier}: \\n {metrics.classification_report(y_test, y_pred_hog_svm)}\\n\"\"\")\n","print(f\"\"\"\\n Classification report for classifier {mlp_classifier}: \\n {metrics.classification_report(y_test, y_pred_mlp)}\\n\"\"\")\n","print(f\"\"\"\\n Classification report for classifier {sift_classifier}: \\n {metrics.classification_report(y_test, y_pred_sift_svm)}\\n\"\"\")\n","\n","print(\"\\n Confusion matrix for HOG+SVM model\")\n","metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_hog_svm)\n","plt.show()\n","print(\"\\n Confusion matrix for HOG+MLP model\")\n","metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_mlp)\n","plt.show()\n","print(\"\\n Confusion matrix for SIFT+SVM model\")\n","metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_sift_svm)\n","plt.show()\n","\n","# Save the trained models\n","dump(svm_classifier, os.path.join(GOOGLE_DRIVE_PATH, 'Models', 'hog-svm.joblib'))\n","dump(mlp_classifier, os.path.join(GOOGLE_DRIVE_PATH, 'Models', 'hog-mlp.joblib'))\n","dump(sift_classifier, os.path.join(GOOGLE_DRIVE_PATH, 'Models', 'sift-svm.joblib'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":654},"id":"XtOI9ItQkaHU","executionInfo":{"status":"error","timestamp":1754586342883,"user_tz":-60,"elapsed":10447,"user":{"displayName":"Aliyyah","userId":"17984600690468507306"}},"outputId":"1898e9c9-a9b7-495f-b5bc-9f22ab33230b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]},{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4121077845.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Colab setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install opencv-python==4.5.5.64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip show opencv-python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]}]}